{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0a2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "def load_data(data):\n",
    "    import pandas as pd\n",
    "\n",
    "    data = pd.read_csv(f\"../files/input/{data}.csv.zip\", compression=\"zip\") \n",
    "\n",
    "    return data\n",
    "\n",
    "train_data = load_data(\"train_data\")\n",
    "test_data = load_data(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784c2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data\n",
    "def clean_data(data):\n",
    "    data = data.copy()\n",
    "    data.rename(columns = {'default payment next month':'default'}, inplace = True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    data[\"EDUCATION\"] = data[\"EDUCATION\"].apply(lambda x: \"others\" if x not in [1,2,3,4] else str(x))\n",
    "    data.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "cleaned_train_data = clean_data(train_data)\n",
    "cleaned_test_data = clean_data(test_data)\n",
    "\n",
    "x_train = cleaned_train_data.drop(columns=[\"default\"])\n",
    "y_train = cleaned_train_data[\"default\"] \n",
    "x_test = cleaned_test_data.drop(columns=[\"default\"])\n",
    "y_test = cleaned_test_data[\"default\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8915f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 359, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'others'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m grid_search\n\u001b[32m     68\u001b[39m pipeline = make_pipeline()\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m estimator = \u001b[43mopt_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m#Guardar modelo\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mopt_params\u001b[39m\u001b[34m(pipeline)\u001b[39m\n\u001b[32m     49\u001b[39m params = {\n\u001b[32m     50\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclassifier__n_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m200\u001b[39m],\n\u001b[32m     51\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclassifier__max_depth\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m10\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[32m     52\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclassifier__min_samples_split\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m2\u001b[39m, \u001b[32m5\u001b[39m],\n\u001b[32m     53\u001b[39m }\n\u001b[32m     55\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     56\u001b[39m     pipeline, \n\u001b[32m     57\u001b[39m     params, \n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     62\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m grid_search\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1028\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1026\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 359, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2971, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1368, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Usuario\\Github\\LAB-09-prediccion-del-default-usando-rf-daimler16\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'others'\n"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "def make_pipeline():\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    cat = [\n",
    "        \"SEX\",\n",
    "        \"EDUCATION\",\n",
    "        \"MARRIAGE\",\n",
    "        \"PAY_0\",\n",
    "        \"PAY_2\",\n",
    "        \"PAY_3\",\n",
    "        \"PAY_4\",\n",
    "        \"PAY_5\",\n",
    "        \"PAY_6\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    to_str = FunctionTransformer(\n",
    "        func=lambda X: X.astype(str),\n",
    "        validate=False)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"to_str\", to_str, cat),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "#Optimización de hiperparametros con validación cruzada\n",
    "def opt_params(pipeline):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "    params = {\n",
    "        'classifier__n_estimators': [200],\n",
    "        'classifier__max_depth': [10, None],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        params, \n",
    "        cv=10, \n",
    "        scoring='balanced_accuracy', \n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "        )\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "pipeline = make_pipeline()\n",
    "estimator = opt_params(pipeline)\n",
    "\n",
    "#Guardar modelo\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "if not os.path.exists(\"./files/models/\"):\n",
    "    os.makedirs(\"./files/models/\")\n",
    "\n",
    "\n",
    "model_name = \"./files/models/model.pkl.gz\"\n",
    "with gzip.open(model_name, 'wb') as f:\n",
    "    pickle.dump(estimator, f)\n",
    "\n",
    "\n",
    "#Calculo de métricas\n",
    "def calc_metrics(estimator):\n",
    "\n",
    "    x_train = cleaned_train_data.drop(columns=[\"default\"])\n",
    "    y_train = cleaned_train_data[\"default\"]\n",
    "    x_test = cleaned_test_data.drop(columns=[\"default\"])\n",
    "    y_test = cleaned_test_data[\"default\"]\n",
    "\n",
    "    from sklearn.metrics import (\n",
    "        precision_score,\n",
    "        balanced_accuracy_score,\n",
    "        recall_score,\n",
    "        f1_score,\n",
    "        confusion_matrix\n",
    "    )\n",
    "\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    out_dir = \"./files/output/\"\n",
    "    out_file = os.path.join(out_dir, \"metrics.json\")\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    # create the json file if it doesn't exist\n",
    "    if not os.path.exists(out_file):\n",
    "        with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    with open(\"files/output/metrics.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "\n",
    "        # ---- TRAIN METRICS ----\n",
    "        y_pred_train = estimator.predict(x_train)\n",
    "        metrics_train = {\n",
    "            \"type\": \"metrics\",\n",
    "            \"dataset\": \"train\",\n",
    "            \"precision\": float(precision_score(y_train, y_pred_train)),\n",
    "            \"balanced_accuracy\": float(balanced_accuracy_score(y_train, y_pred_train)),\n",
    "            \"recall\": float(recall_score(y_train, y_pred_train)),\n",
    "            \"f1_score\": float(f1_score(y_train, y_pred_train)),\n",
    "        }\n",
    "        file.write(json.dumps(metrics_train) + \"\\n\")\n",
    "\n",
    "        cm = confusion_matrix(y_train, y_pred_train)\n",
    "        cm_train = {\n",
    "            \"type\": \"cm_matrix\",\n",
    "            \"dataset\": \"train\",\n",
    "            \"true_0\": {\n",
    "                \"predicted_0\": int(cm[0][0]),\n",
    "                \"predicted_1\": int(cm[0][1]),\n",
    "            },\n",
    "            \"true_1\": {\n",
    "                \"predicted_0\": int(cm[1][0]),\n",
    "                \"predicted_1\": int(cm[1][1]),\n",
    "            },\n",
    "        }\n",
    "        file.write(json.dumps(cm_train) + \"\\n\")\n",
    "\n",
    "        y_pred_test = estimator.predict(x_test)\n",
    "        metrics_test = {\n",
    "            \"type\": \"metrics\",\n",
    "            \"dataset\": \"test\",\n",
    "            \"precision\": float(precision_score(y_test, y_pred_test)),\n",
    "            \"balanced_accuracy\": float(balanced_accuracy_score(y_test, y_pred_test)),\n",
    "            \"recall\": float(recall_score(y_test, y_pred_test)),\n",
    "            \"f1_score\": float(f1_score(y_test, y_pred_test)),\n",
    "        }\n",
    "        file.write(json.dumps(metrics_test) + \"\\n\")\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        cm_test = {\n",
    "            \"type\": \"cm_matrix\",\n",
    "            \"dataset\": \"test\",\n",
    "            \"true_0\": {\n",
    "                \"predicted_0\": int(cm[0][0]),\n",
    "                \"predicted_1\": int(cm[0][1]),\n",
    "            },\n",
    "            \"true_1\": {\n",
    "                \"predicted_0\": int(cm[1][0]),\n",
    "                \"predicted_1\": int(cm[1][1]),\n",
    "            },\n",
    "        }\n",
    "        file.write(json.dumps(cm_test) + \"\\n\")\n",
    "\n",
    "calc_metrics(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
